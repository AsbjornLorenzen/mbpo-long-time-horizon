name: "mbpo"

normalize: false
normalize_double_precision: false
target_is_delta: false
learned_rewards: false
freq_train_model: ${overrides.freq_train_model}
real_data_ratio: ${overrides.real_data_ratio}

sac_samples_action: true
initial_exploration_steps: 1000
random_initial_explore: false
num_eval_episodes: 10

dataset_size: 1000000


#Periodic network reset of SAC agent
critic_reset: false
#critic_reset_factor = crf, only has effect if critic_reset = true
# new_weights = (1-crf)*old_weights+crf*new_weights
critic_reset_factor: 1.0
critic_reset_every_step: 20000 # env_steps

# --------------------------------------------
#          SAC Agent configuration
# --------------------------------------------
agent:
  num_inputs: ???
  action_space:
    low: ???
    high: ???
    shape: ???
  args:
    layernorm: false 
    gamma: ${overrides.sac_gamma}
    tau: ${overrides.sac_tau}
    alpha: ${overrides.sac_alpha}
    policy: ${overrides.sac_policy}
    target_update_interval: ${overrides.sac_target_update_interval}
    automatic_entropy_tuning: ${overrides.sac_automatic_entropy_tuning}
    target_entropy: ${overrides.sac_target_entropy}
    hidden_size: ${overrides.sac_hidden_size}
    device: ${device}
    lr: ${overrides.sac_lr}